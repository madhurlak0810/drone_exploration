# ğŸš Autonomous Drone Exploration with Reinforcement Learning

A comprehensive ROS2 package for autonomous drone exploration using Q-learning and SLAM mapping.

## ğŸŒŸ Features

- **Q-Learning Agent**: Autonomous exploration using reinforcement learning
- **SLAM Integration**: Real-time mapping with SLAM Toolbox
- **Gazebo Simulation**: Complete 3D simulation environment  
- **Performance Metrics**: Real-time exploration tracking and analysis
- **Modular Design**: Clean, extensible codebase

## ğŸ“‹ System Requirements

- **OS**: Ubuntu 22.04 LTS
- **ROS2**: Humble Hawksbill
- **Python**: 3.10+
- **Gazebo**: Garden/Fortress

## ğŸš€ Quick Installation

### 1. Install Dependencies

```bash
# Install ROS2 Humble and required packages
sudo apt update
sudo apt install ros-humble-desktop ros-humble-gazebo-ros-pkgs \
  ros-humble-slam-toolbox ros-humble-navigation2 \
  ros-humble-nav2-bringup ros-humble-joint-state-publisher \
  ros-humble-robot-state-publisher ros-humble-xacro \
  python3-colcon-common-extensions python3-numpy python3-matplotlib

# Optional: Install RTABMap for advanced SLAM (requires additional setup)
# sudo apt install ros-humble-rtabmap-ros
```

### 2. Build Package

```bash
# Navigate to workspace and build
cd ~/drone_ws
source /opt/ros/humble/setup.bash
colcon build --packages-select drone_rl
source install/setup.bash
```

### 3. Launch Simulation

```bash
# Launch the complete exploration environment
ros2 launch drone_rl sim_launch.py

# Or run headless for better performance
ros2 launch drone_rl sim_launch.py headless:=true rviz:=false
```

## ğŸ“Š Monitor Performance

```bash
# Real-time metrics
ros2 topic echo /exploration_metrics

# View saved metrics and plots
ls ~/drone_ws/metrics/
```

## ğŸ® Manual Control (Optional)

```bash
# Install teleop tools
sudo apt install ros-humble-teleop-twist-keyboard

# Manual control for testing
ros2 run teleop_twist_keyboard teleop_twist_keyboard
```

## ğŸ—ï¸ Architecture

```
drone_rl/
â”œâ”€â”€ drone_rl/
â”‚   â”œâ”€â”€ q_learning_agent.py      # Main RL agent
â”‚   â”œâ”€â”€ environment_interface.py  # Environment state processing
â”‚   â””â”€â”€ exploration_metrics.py    # Performance tracking
â”œâ”€â”€ launch/
â”‚   â””â”€â”€ sim_launch.py            # Complete launch configuration
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ drone_config.yaml       # Agent parameters
â”‚   â””â”€â”€ drone_exploration.rviz   # RViz configuration
â”œâ”€â”€ urdf/
â”‚   â””â”€â”€ drone.urdf.xacro         # Robot description
â”œâ”€â”€ worlds/
â”‚   â””â”€â”€ exploration_world.world  # Gazebo simulation world
â””â”€â”€ scripts/
    â””â”€â”€ quick_start.sh           # Quick setup script
```

## âš™ï¸ Configuration

Edit `config/drone_config.yaml` to customize:

- **Q-Learning parameters**: learning rate, epsilon, rewards
- **Environment settings**: sensor ranges, safety distances  
- **Control parameters**: velocities, update frequencies

## ğŸ“ˆ Key Parameters

| Parameter | Default | Description |
|-----------|---------|-------------|
| `learning_rate` | 0.1 | Q-learning learning rate |
| `epsilon` | 0.3 | Exploration vs exploitation rate |
| `safety_distance` | 0.3m | Minimum obstacle distance |
| `max_linear_velocity` | 0.5 m/s | Maximum forward speed |

## ğŸ”„ Experiment Workflow

1. **Launch**: Start simulation with `ros2 launch drone_rl sim_launch.py`
2. **Monitor**: Watch live mapping in RViz and metrics in terminal
3. **Analyze**: Review saved metrics in `~/drone_ws/metrics/`
4. **Iterate**: Adjust parameters and repeat

## ğŸ“Š Metrics Tracked

- **Coverage Percentage**: Amount of environment mapped
- **Exploration Efficiency**: Coverage per unit time
- **Collision Rate**: Safety performance
- **Q-Learning Progress**: Reward accumulation and epsilon decay

## ğŸ”§ Troubleshooting

### Common Issues

**Q-table not saving**: Check file permissions in `~/drone_ws/`

**SLAM not working**: Ensure topics are properly remapped:
```bash
ros2 topic list | grep -E "(scan|odom|map)"
```

**Poor exploration**: Adjust reward function in `drone_config.yaml`

**Gazebo crashes**: Reduce physics update rate or run headless

### Performance Tips

- Run headless (`headless:=true`) for better performance
- Adjust `control_frequency` based on hardware capabilities
- Monitor CPU/memory usage during long experiments

## ğŸ¯ Future Enhancements

- [ ] **PPO Implementation**: Upgrade to continuous action space
- [ ] **3D Exploration**: Add altitude control for true 3D mapping
- [ ] **Multi-Agent**: Support for multiple drones
- [ ] **Real Robot**: Hardware deployment scripts
- [ ] **Advanced Rewards**: Sophisticated reward shaping

## ğŸ“ Publications & References

This implementation is based on principles from:
- Q-Learning for robotics navigation
- SLAM Toolbox for real-time mapping
- Gazebo simulation best practices

## ğŸ¤ Contributing

Feel free to submit issues, feature requests, and pull requests!

## ğŸ“„ License

MIT License - see LICENSE file for details

---

**Happy Exploring!** ğŸšâœ¨

For questions or support, please open an issue in the repository.